{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import copy\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from scipy import misc\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(paths, labels, nb_samples=None, shuffle=True):\n",
    "    \"\"\"\n",
    "    Takes a set of character folders and labels and returns paths to image files\n",
    "    paired with labels.\n",
    "    Args:\n",
    "        paths: A list of character folders\n",
    "        labels: List or numpy array of same length as paths\n",
    "        nb_samples: Number of images to retrieve per character\n",
    "    Returns:\n",
    "        List of (label, image_path) tuples\n",
    "    \"\"\"\n",
    "    if nb_samples is not None:\n",
    "        sampler = lambda x: random.sample(x, nb_samples)\n",
    "    else:\n",
    "        sampler = lambda x: x\n",
    "    images_labels = [(i, os.path.join(path, image))\n",
    "                     for i, path in zip(labels, paths)\n",
    "                     for image in sampler(os.listdir(path))]\n",
    "    if shuffle:\n",
    "        random.shuffle(images_labels)\n",
    "    return images_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_file_to_array(filename, dim_input):\n",
    "    \"\"\"\n",
    "    Takes an image path and returns numpy array\n",
    "    Args:\n",
    "        filename: Image filename\n",
    "        dim_input: Flattened shape of image\n",
    "    Returns:\n",
    "        1 channel image\n",
    "    \"\"\"\n",
    "    image = misc.imread(filename)\n",
    "    image = image.reshape([dim_input])\n",
    "    image = image.astype(np.float32) / 255.0\n",
    "    image = 1.0 - image\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(logs, NUM_CLASSES, NUM_SAMPLES):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    steps = [x[0] for x in logs]\n",
    "    train_loss = [x[1] for x in logs]\n",
    "    test_loss = [x[2] for x in logs]\n",
    "    acc = [x[3] for x in logs]\n",
    "    \n",
    "    ax.plot(steps, train_loss, label = 'train loss')\n",
    "    ax.plot(steps, test_loss, label = 'test_loss')\n",
    "    ax.plot(steps, acc, label = 'accuracy')\n",
    "    ax.set(xlabel='Iterations', title='MANN: {}-way classification, {}-shot'.format(NUM_CLASSES, NUM_SAMPLES))\n",
    "    \n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(object):\n",
    "    \n",
    "    def __init__(self, num_classes, num_samples_per_class):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_classes: Number of classes for classification (K-way)\n",
    "            num_samples_per_class: num samples to generate per class in one batch\n",
    "            batch_size: size of meta batch size (e.g. number of functions)\n",
    "        \"\"\"\n",
    "        self.num_samples_per_class = num_samples_per_class\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        data_folder = './omniglot_resized'\n",
    "        \n",
    "        self.img_size = (28, 28)\n",
    "        self.dim_input = np.prod(self.img_size)\n",
    "        self.dim_output = self.num_classes\n",
    "        \n",
    "        character_folders = [os.path.join(data_folder, family, character)\n",
    "                             for family in os.listdir(data_folder)\n",
    "                             if os.path.isdir(os.path.join(data_folder, family))\n",
    "                             for character in os.listdir(os.path.join(data_folder, family))\n",
    "                             if os.path.isdir(os.path.join(data_folder, family, character))]\n",
    "        \n",
    "        random.seed(1)\n",
    "        random.shuffle(character_folders)\n",
    "        \n",
    "        # using roughly 20% of data for meta-testing (1200:423)\n",
    "        num_train = 1200\n",
    "        \n",
    "        self.metatrain_character_folders = character_folders[:num_train]\n",
    "        self.metatest_character_folders = character_folders[num_train:]\n",
    "        \n",
    "    def sample_batch(self, batch_type, batch_size):\n",
    "        \"\"\"\n",
    "        Samples a batch for training or testing\n",
    "        Args:\n",
    "            batch_type: train/test\n",
    "        Returns:\n",
    "            A a tuple of (1) Image batch and (2) Label batch where\n",
    "            image batch has shape [B, K, N, 784] and label batch has shape [B, K, N, N]\n",
    "            where B is batch size, K is number of samples per class, N is number of classes\n",
    "        \"\"\"\n",
    "        if batch_type == \"train\":\n",
    "            folders = self.metatrain_character_folders\n",
    "        elif batch_type == \"test\":\n",
    "            folders = self.metatest_character_folders\n",
    "            \n",
    "        B, K, N = batch_size, self.num_samples_per_class, self.num_classes\n",
    "        \n",
    "        all_image_batches = np.zeros((B, K, N, self.dim_input))\n",
    "        all_label_batches = np.zeros((B, K, N, N))\n",
    "\n",
    "        for batch_idx in range(B):\n",
    "            sampled_classes = np.random.choice(folders, N, replace = False)\n",
    "            one_hot_labels = np.eye(N)\n",
    "\n",
    "            images_and_labels = get_images(sampled_classes, one_hot_labels, nb_samples=K, shuffle=False)\n",
    "            \n",
    "            images_train = []\n",
    "            images_test = []\n",
    "            labels_train = []\n",
    "            labels_test = []\n",
    "            \n",
    "            for i, (label, image_path) in enumerate(images_and_labels):\n",
    "                if i % K == 0:\n",
    "                    images_test.append(image_path)\n",
    "                    labels_test.append(label)\n",
    "                else:\n",
    "                    images_train.append(image_path)\n",
    "                    labels_train.append(label)\n",
    "\n",
    "            images_train, labels_train = shuffle(images_train, labels_train)\n",
    "            images_test, labels_test = shuffle(images_test, labels_test)\n",
    " \n",
    "            images_train = [image_file_to_array(x, self.dim_input) for x in images_train]\n",
    "            images_test = [image_file_to_array(x, self.dim_input) for x in images_test]\n",
    "            \n",
    "            image_batches_train = np.array(images_train)\n",
    "            label_batches_train = np.array(labels_train)\n",
    "            image_batches_test = np.array(images_test)\n",
    "            label_batches_test = np.array(labels_test)\n",
    "            \n",
    "            image_batches = np.concatenate([image_batches_train, image_batches_test], axis = 0).reshape(K, N, self.dim_input)\n",
    "            label_batches = np.concatenate([label_batches_train, label_batches_test], axis = 0).reshape(K, N, N)\n",
    "            \n",
    "            all_image_batches[batch_idx, :, :, :] = image_batches\n",
    "            all_label_batches[batch_idx, :, :, :] = label_batches\n",
    "                \n",
    "        return all_image_batches, all_label_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "num_samples_per_class = 5\n",
    "batch_size = 16\n",
    "\n",
    "generator = DataGenerator(num_classes, num_samples_per_class)\n",
    "batch_images, batch_labels = generator.sample_batch(\"train\", batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = 0\n",
    "image_index = -1\n",
    "sample_images, sample_labels = batch_images[batch_idx, image_index, :, :], batch_labels[batch_idx, image_index, :, :]\n",
    "for i, j in zip(sample_images, sample_labels):\n",
    "    print(j)\n",
    "    plt.imshow(np.uint8(i.reshape(28, 28)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MANN(tf.keras.Model):\n",
    "    def __init__(self, num_classes, samples_per_class, lstm_size, bidirectional = False):\n",
    "        super(MANN, self).__init__()\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_classes = num_classes\n",
    "        self.samples_per_class = samples_per_class\n",
    "        \n",
    "        if self.bidirectional:\n",
    "            self.lstm_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_size, dropout = 0.5, return_sequences = True))\n",
    "            self.lstm_2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_size, dropout = 0.5, return_sequences = True))\n",
    "            self.dense_1 = tf.keras.layers.Dense(num_classes)\n",
    "        else:\n",
    "            self.lstm_1 = tf.keras.layers.LSTM(lstm_size, return_sequences = True)\n",
    "            self.lstm_2 = tf.keras.layers.LSTM(num_classes, return_sequences = True)\n",
    "        \n",
    "    def call(self, input_images, input_labels):\n",
    "        \"\"\"\n",
    "        MANN\n",
    "        Args:\n",
    "            input_images: [B, K+1, N, 784] flattened images\n",
    "            labels: [B, K+1, N, N] ground truth labels\n",
    "        Returns:\n",
    "            [B, K+1, N, N] predictions\n",
    "        \"\"\"\n",
    "        B, Kplusone, N, D = input_images.shape\n",
    "        K = Kplusone - 1\n",
    "        input_labels = tf.dtypes.cast(input_labels, tf.float32)\n",
    "        input_labels = tf.concat([input_labels[:, :-1],\n",
    "                                  tf.zeros_like(input_labels[:, -1:])], axis = 1)  \n",
    "        x = tf.concat([input_images, input_labels], axis = 3)\n",
    "        x = tf.reshape(x, (B, Kplusone * N, D + N))\n",
    "        x = self.lstm_2(self.lstm_1(x))\n",
    "           \n",
    "        if self.bidirectional:\n",
    "            x = self.dense_1(x)\n",
    "        out = tf.reshape(x, (B, Kplusone, N, N))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(preds, labels):\n",
    "    \"\"\"\n",
    "    Computes MANN loss\n",
    "    Args:\n",
    "        preds: [B, K+1, N, N] network output\n",
    "        labels: [B, K+1, N, N] labels\n",
    "    Returns:\n",
    "        scalar loss\n",
    "    \"\"\"\n",
    "    last_y_preds = preds[:, -1:]\n",
    "    last_y_labels = labels[:, -1:]\n",
    "    loss = tf.keras.losses.categorical_crossentropy(last_y_labels, last_y_preds, from_logits=True)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inputs, labels, model, loss_object, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, labels, training=True)\n",
    "        loss = loss_object(predictions, labels)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "    \n",
    "@tf.function\n",
    "def test_step(inputs, labels, model, loss_object):\n",
    "    predictions = model(inputs, labels, training=False)\n",
    "    loss = loss_object(predictions, labels)\n",
    "    return loss, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MANN(NUM_CLASSES = 5, NUM_SAMPLES = 1, META_BATCH_SIZE = 64, ITERATIONS = 50000, LSTM_SIZE = 128, BIDIRECTIONAL = False):\n",
    "    \"\"\"\n",
    "    NUM_CLASSES        'number of classes used in classification (e.g. 5-way classification)\n",
    "    NUM_SAMPLES        'number of examples used for inner gradient update (K for K-shot learning).'\n",
    "    META_BATCH_SIZE    'number of N-way classification tasks per batch'\n",
    "    \"\"\"\n",
    "    \n",
    "    logs = []\n",
    "\n",
    "    data_generator = DataGenerator(NUM_CLASSES, NUM_SAMPLES + 1)\n",
    "    \n",
    "    o = MANN(NUM_CLASSES, NUM_SAMPLES + 1, LSTM_SIZE, BIDIRECTIONAL)\n",
    "    summarized = False\n",
    "    loss = loss_function\n",
    "    optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "\n",
    "    for step in range(ITERATIONS):\n",
    "        images_batch, labels_batch = data_generator.sample_batch('train', META_BATCH_SIZE)\n",
    "        train_loss = train_step(images_batch, labels_batch, o, loss, optimizer)\n",
    "        if not summarized:\n",
    "            o.summary()\n",
    "            summarized = True\n",
    "            \n",
    "        if step % 1000 == 0:\n",
    "            print(\"*\" * 5 + \"Iteration no. {}\".format(step) + \"*\" * 5)\n",
    "\n",
    "            images_batch_test, labels_batch_test = data_generator.sample_batch('test', 300)\n",
    "            test_loss, preds = test_step(images_batch_test, labels_batch_test, o, loss)\n",
    "            preds = preds.numpy().reshape(-1, NUM_SAMPLES + 1, NUM_CLASSES, NUM_CLASSES)\n",
    "            preds = preds[:, -1, :, :].argmax(2)\n",
    "            labels_batch_test = labels_batch_test[:, -1, :, :].argmax(2)\n",
    "\n",
    "            print(\"Train Loss: {} Test Loss: {}\".format(train_loss.numpy(), test_loss.numpy()))\n",
    "            accuracy = (1.0 * (preds == labels_batch_test)).mean()\n",
    "            print(\"Test Accuracy\", accuracy)\n",
    "\n",
    "            logs.append((step, train_loss, test_loss, accuracy))\n",
    "\n",
    "    plot_results(logs, NUM_CLASSES, NUM_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_MANN(NUM_CLASSES = 3, NUM_SAMPLES = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sample_env",
   "language": "python",
   "name": "sample_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
