{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/damian/Code/stanford_ml_mt/sample_env/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from tensorflow.keras import layers\n",
    "from scipy import misc\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(paths, labels, nb_samples=None, shuffle=True):\n",
    "    \"\"\"\n",
    "    Takes a set of character folders and labels and returns paths to image files\n",
    "    paired with labels.\n",
    "    Args:\n",
    "        paths: A list of character folders\n",
    "        labels: List or numpy array of same length as paths\n",
    "        nb_samples: Number of images to retrieve per character\n",
    "    Returns:\n",
    "        List of (label, image_path) tuples\n",
    "    \"\"\"\n",
    "    if nb_samples is not None:\n",
    "        sampler = lambda x: random.sample(x, nb_samples)\n",
    "    else:\n",
    "        sampler = lambda x: x\n",
    "    images_labels = [(i, os.path.join(path, image))\n",
    "                     for i, path in zip(labels, paths)\n",
    "                     for image in sampler(os.listdir(path))]\n",
    "    if shuffle:\n",
    "        random.shuffle(images_labels)\n",
    "    return images_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_file_to_array(filename, dim_input):\n",
    "    \"\"\"\n",
    "    Takes an image path and returns numpy array\n",
    "    Args:\n",
    "        filename: Image filename\n",
    "        dim_input: Flattened shape of image\n",
    "    Returns:\n",
    "        1 channel image\n",
    "    \"\"\"\n",
    "    image = misc.imread(filename)\n",
    "    image = image.reshape([dim_input])\n",
    "    image = image.astype(np.float32) / 255.0\n",
    "    image = 1.0 - image\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(logs, NUM_CLASSES, NUM_SAMPLES):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    steps = [x[0] for x in logs]\n",
    "    train_loss = [x[1] for x in logs]\n",
    "    test_loss = [x[2] for x in logs]\n",
    "    acc = [x[3] for x in logs]\n",
    "    ax.plot(steps, train_loss, label = 'train loss')\n",
    "    ax.plot(steps, test_loss, label = 'test_loss')\n",
    "    ax.plot(steps, acc, label = 'accuracy')\n",
    "    ax.set(xlabel='Iterations', \n",
    "           title='MANN: {}-way classification, {}-shot'.format(NUM_CLASSES, NUM_SAMPLES))\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(object):\n",
    "    \n",
    "    def __init__(self, num_classes, num_samples_per_class):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_classes: Number of classes for classification (K-way)\n",
    "            num_samples_per_class: num samples to generate per class in one batch\n",
    "            batch_size: size of meta batch size (e.g. number of functions)\n",
    "        \"\"\"\n",
    "        self.num_samples_per_class = num_samples_per_class\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        data_folder = './omniglot_resized'\n",
    "        \n",
    "        self.img_size = (28, 28)\n",
    "        self.dim_input = np.prod(self.img_size)\n",
    "        self.dim_output = self.num_classes\n",
    "        \n",
    "        character_folders = [os.path.join(data_folder, family, character)\n",
    "                             for family in os.listdir(data_folder)\n",
    "                             if os.path.isdir(os.path.join(data_folder, family))\n",
    "                             for character in os.listdir(os.path.join(data_folder, family))\n",
    "                             if os.path.isdir(os.path.join(data_folder, family, character))]\n",
    "        \n",
    "        random.seed(1)\n",
    "        random.shuffle(character_folders)\n",
    "        \n",
    "        # using roughly 20% of data for meta-testing (1200:423)\n",
    "        num_train = 1200\n",
    "        \n",
    "        self.metatrain_character_folders = character_folders[:num_train]\n",
    "        self.metatest_character_folders = character_folders[num_train:]\n",
    "        \n",
    "    def sample_batch(self, batch_type, batch_size):\n",
    "        \"\"\"\n",
    "        Samples a batch for training or testing\n",
    "        Args:\n",
    "            batch_type: train/test\n",
    "        Returns:\n",
    "            A a tuple of (1) Image batch and (2) Label batch where\n",
    "            image batch has shape [B, K, N, 784] and label batch has shape [B, K, N, N]\n",
    "            where B is batch size, K is number of samples per class, N is number of classes\n",
    "        \"\"\"\n",
    "        if batch_type == \"train\":\n",
    "            folders = self.metatrain_character_folders\n",
    "        elif batch_type == \"test\":\n",
    "            folders = self.metatest_character_folders\n",
    "            \n",
    "        B, K, N = batch_size, self.num_samples_per_class, self.num_classes\n",
    "        \n",
    "        all_image_batches = np.zeros((B, K, N, self.dim_input))\n",
    "        all_label_batches = np.zeros((B, K, N, N))\n",
    "\n",
    "        for batch_idx in range(B):\n",
    "            sampled_classes = np.random.choice(folders, N, replace = False)\n",
    "            one_hot_labels = np.eye(N)\n",
    "            images_and_labels = get_images(sampled_classes, one_hot_labels, nb_samples=K, shuffle=False)\n",
    "            \n",
    "            images_train = []\n",
    "            images_test = []\n",
    "            labels_train = []\n",
    "            labels_test = []\n",
    "            \n",
    "            for i, (label, image_path) in enumerate(images_and_labels):\n",
    "                if i % K == 0:\n",
    "                    images_test.append(image_path)\n",
    "                    labels_test.append(label)\n",
    "                else:\n",
    "                    images_train.append(image_path)\n",
    "                    labels_train.append(label)\n",
    "            \n",
    "            images_train, labels_train = shuffle(images_train, labels_train)\n",
    "            images_test, labels_test = shuffle(images_test, labels_test)\n",
    "            \n",
    "            #[print(x,y) for x,y in zip(images_train, labels_train)]\n",
    "            #print('--------')\n",
    "            #[print(x,y) for x,y in zip(images_test, labels_test)]\n",
    "            #print('*********')\n",
    "            \n",
    "            images_train = [image_file_to_array(x, self.dim_input) for x in images_train]\n",
    "            images_test = [image_file_to_array(x, self.dim_input) for x in images_test]\n",
    "            \n",
    "            image_batches_train = np.array(images_train)\n",
    "            label_batches_train = np.array(labels_train)\n",
    "            image_batches_test = np.array(images_test)\n",
    "            label_batches_test = np.array(labels_test)\n",
    "            \n",
    "            image_batches = np.concatenate([image_batches_train, image_batches_test], axis = 0).reshape(K, N, self.dim_input)\n",
    "            label_batches = np.concatenate([label_batches_train, label_batches_test], axis = 0).reshape(K, N, N)\n",
    "            \n",
    "            all_image_batches[batch_idx, :, :, :] = image_batches\n",
    "            all_label_batches[batch_idx, :, :, :] = label_batches\n",
    "                \n",
    "        return all_image_batches, all_label_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/damian/Code/stanford_ml_mt/sample_env/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "num_classes = 4\n",
    "num_samples_per_class = 5\n",
    "batch_size = 16\n",
    "\n",
    "generator = DataGenerator(num_classes, num_samples_per_class)\n",
    "batch_images, batch_labels = generator.sample_batch(\"train\", batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_idx = 0\n",
    "image_index = -3\n",
    "sample_images, sample_labels = batch_images[batch_idx, image_index, :, :], batch_labels[batch_idx, image_index, :, :]\n",
    "for i, j in zip(sample_images, sample_labels):\n",
    "    print(j)\n",
    "    plt.imshow(np.uint8(i.reshape(28, 28)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MANN(tf.keras.Model):\n",
    "    def __init__(self, num_classes, samples_per_class, lstm_size):\n",
    "        super(MANN, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.samples_per_class = samples_per_class\n",
    "        self.layer1 = tf.keras.layers.LSTM(lstm_size, return_sequences = True)\n",
    "        self.layer2 = tf.keras.layers.LSTM(num_classes, return_sequences = True)\n",
    "        \n",
    "    def call(self, input_images, input_labels):\n",
    "        \"\"\"\n",
    "        MANN\n",
    "        Args:\n",
    "            input_images: [B, K+1, N, 784] flattened images\n",
    "            labels: [B, K+1, N, N] ground truth labels\n",
    "        Returns:\n",
    "            [B, K+1, N, N] predictions\n",
    "        \"\"\"\n",
    "        B, Kplusone, N, D = input_images.shape\n",
    "        no_non_zero_labels = Kplusone*N-N\n",
    "\n",
    "        input_images = tf.reshape(input_images, (-1, Kplusone * N, D))\n",
    "        input_labels = tf.reshape(input_labels, (-1, Kplusone * N, N))\n",
    "        input_labels = tf.concat([input_labels[:, :no_non_zero_labels,:], \n",
    "                                  tf.zeros_like(input_labels[:,no_non_zero_labels:,:])], axis = 1)\n",
    "\n",
    "        x = tf.concat([input_images, input_labels], axis=2)\n",
    "        out = self.layer2(self.layer1(x))\n",
    "        out = tf.reshape(out, (-1, Kplusone, N, N))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nclass MANN_CONV(tf.keras.Model):\\n    def __init__(self, num_classes, samples_per_class, lstm_size):\\n        super(MANN, self).__init__()\\n        self.num_classes = num_classes\\n        self.samples_per_class = samples_per_class\\n\\n        self.layer1 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer = 'he_uniform',\\n                                             input_shape(28,28,1))\\n        \\n        self.layer11 = tf.keras.layers.MaxPooling2D((2,2))\\n        self.layer12 = tf.keras.layers.Flatten()\\n        self.layer2 = tf.keras.layers.LSTM(lstm_size, return_sequences = True)\\n        self.layer3 = tf.keras.layers.LSTM(num_classes, return_sequences = True)\\n        \\n    def call(self, input_images, input_labels):\\n        MANN\\n        Args:\\n            input_images: [B, K+1, N, 784] flattened images\\n            labels: [B, K+1, N, N] ground truth labels\\n        Returns:\\n            [B, K+1, N, N] predictions\\n\\n        B, Kplusone, N, D = input_images.shape\\n        X = 28\\n        input_images = tf.reshape(input_images, (B * Kplusone * N, D))\\n        input_images = tf.reshape(input_images, (-1, X, X, 1))\\n        x = self.layer12(self.layer11(self.layer1(input_images)))\\n        x = tf.reshape(x, (-1, Kplusone * N, D))\\n        \\n        \\n        \\n        no_non_zero_labels = Kplusone*N-N\\n        input_labels = tf.reshape(input_labels, (-1, Kplusone * N, N))\\n        input_labels = tf.concat([input_labels[:, :no_non_zero_labels,:], \\n                                  tf.zeros_like(input_labels[:,no_non_zero_labels:,:])], axis = 1)\\n\\n        x = tf.concat([x, input_labels], axis=2)\\n        out = self.layer3(self.layer2(x))\\n        out = tf.reshape(out, (-1, Kplusone, N, N))\\n        \\n        return out\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "class MANN_CONV(tf.keras.Model):\n",
    "    def __init__(self, num_classes, samples_per_class, lstm_size):\n",
    "        super(MANN, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.samples_per_class = samples_per_class\n",
    "\n",
    "        self.layer1 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer = 'he_uniform',\n",
    "                                             input_shape(28,28,1))\n",
    "        \n",
    "        self.layer11 = tf.keras.layers.MaxPooling2D((2,2))\n",
    "        self.layer12 = tf.keras.layers.Flatten()\n",
    "        self.layer2 = tf.keras.layers.LSTM(lstm_size, return_sequences = True)\n",
    "        self.layer3 = tf.keras.layers.LSTM(num_classes, return_sequences = True)\n",
    "        \n",
    "    def call(self, input_images, input_labels):\n",
    "        MANN\n",
    "        Args:\n",
    "            input_images: [B, K+1, N, 784] flattened images\n",
    "            labels: [B, K+1, N, N] ground truth labels\n",
    "        Returns:\n",
    "            [B, K+1, N, N] predictions\n",
    "\n",
    "        B, Kplusone, N, D = input_images.shape\n",
    "        X = 28\n",
    "        input_images = tf.reshape(input_images, (B * Kplusone * N, D))\n",
    "        input_images = tf.reshape(input_images, (-1, X, X, 1))\n",
    "        x = self.layer12(self.layer11(self.layer1(input_images)))\n",
    "        x = tf.reshape(x, (-1, Kplusone * N, D))\n",
    "        \n",
    "        \n",
    "        \n",
    "        no_non_zero_labels = Kplusone*N-N\n",
    "        input_labels = tf.reshape(input_labels, (-1, Kplusone * N, N))\n",
    "        input_labels = tf.concat([input_labels[:, :no_non_zero_labels,:], \n",
    "                                  tf.zeros_like(input_labels[:,no_non_zero_labels:,:])], axis = 1)\n",
    "\n",
    "        x = tf.concat([x, input_labels], axis=2)\n",
    "        out = self.layer3(self.layer2(x))\n",
    "        out = tf.reshape(out, (-1, Kplusone, N, N))\n",
    "        \n",
    "        return out\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(preds, labels):\n",
    "    \"\"\"\n",
    "    Computes MANN loss\n",
    "    Args:\n",
    "        preds: [B, K+1, N, N] network output\n",
    "        labels: [B, K+1, N, N] labels\n",
    "    Returns:\n",
    "        scalar loss\n",
    "    \"\"\"\n",
    "    last_y_preds = preds[:, -1, :,:]\n",
    "    last_y_labels = labels[:, -1, :,:]\n",
    "    loss = tf.keras.losses.categorical_crossentropy(last_y_labels, last_y_preds, from_logits=True)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MANN(NUM_CLASSES = 5, NUM_SAMPLES = 1, META_BATCH_SIZE = 16, ITERATIONS = 50000, LSTM_SIZE = 128):\n",
    "    \"\"\"\n",
    "    NUM_CLASSES        'number of classes used in classification (e.g. 5-way classification)\n",
    "    NUM_SAMPLES        'number of examples used for inner gradient update (K for K-shot learning).'\n",
    "    META_BATCH_SIZE    'number of N-way classification tasks per batch'\n",
    "    \"\"\"\n",
    "    \n",
    "    logs = []\n",
    "\n",
    "    ims = tf.placeholder(tf.float32, shape=( None, NUM_SAMPLES + 1, NUM_CLASSES, 784))\n",
    "    labels = tf.placeholder(tf.float32, shape=( None, NUM_SAMPLES + 1, NUM_CLASSES, NUM_CLASSES))\n",
    "\n",
    "    data_generator = DataGenerator(NUM_CLASSES, NUM_SAMPLES + 1)\n",
    "    \n",
    "    o = MANN(NUM_CLASSES, NUM_SAMPLES + 1, LSTM_SIZE)\n",
    "    out = o(ims, labels)\n",
    "\n",
    "    loss = loss_function(out, labels)\n",
    "    optim = tf.train.AdamOptimizer(0.001)\n",
    "    optimizer_step = optim.minimize(loss)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        for step in range(ITERATIONS):\n",
    "            images_batch, labels_batch = data_generator.sample_batch('train', META_BATCH_SIZE)\n",
    "            feed = {ims: images_batch.astype(np.float32), labels: labels_batch.astype(np.float32)}\n",
    "            _, train_loss = sess.run([optimizer_step, loss], feed)\n",
    "            if step % 5000 == 0:\n",
    "                print(\"*\" * 5 + \"Iteration no. {}\".format(step) + \"*\" * 5)\n",
    "\n",
    "                images_batch_test, labels_batch_test = data_generator.sample_batch('test', 200)\n",
    "\n",
    "                feed = {ims: images_batch_test.astype(np.float32), labels: labels_batch_test.astype(np.float32)}\n",
    "                pred, test_loss = sess.run([out, loss], feed)\n",
    "\n",
    "                print(\"Train Loss: {} Test Loss: {}\".format(train_loss, test_loss))\n",
    "                pred = pred[:, -1, :, :].argmax(2)\n",
    "                l = labels_batch_test[:, -1, :, :].argmax(2)\n",
    "                acc = (1.0 * (pred == l)).mean()\n",
    "                print(\"Test Accuracy\", acc)\n",
    "\n",
    "                logs.append((step, train_loss, test_loss, acc))\n",
    "\n",
    "    plot_results(logs, NUM_CLASSES, NUM_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/damian/Code/stanford_ml_mt/sample_env/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/damian/Code/stanford_ml_mt/sample_env/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Iteration no. 0*****\n",
      "Train Loss: 1.1023725271224976 Test Loss: 1.106208086013794\n",
      "Test Accuracy 0.3283333333333333\n",
      "*****Iteration no. 5000*****\n",
      "Train Loss: 1.0986278057098389 Test Loss: 1.0986096858978271\n",
      "Test Accuracy 0.33166666666666667\n"
     ]
    }
   ],
   "source": [
    "# fix K vary N\n",
    "NUM_SAMPLES = 1\n",
    "NUM_CLASSES = 3\n",
    "train_MANN(NUM_CLASSES, NUM_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sample_env",
   "language": "python",
   "name": "sample_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
