{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import copy\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from scipy import misc\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(paths, labels, nb_samples=None, shuffle=True):\n",
    "    \"\"\"\n",
    "    Takes a set of character folders and labels and returns paths to image files\n",
    "    paired with labels.\n",
    "    Args:\n",
    "        paths: A list of character folders\n",
    "        labels: List or numpy array of same length as paths\n",
    "        nb_samples: Number of images to retrieve per character\n",
    "    Returns:\n",
    "        List of (label, image_path) tuples\n",
    "    \"\"\"\n",
    "    if nb_samples is not None:\n",
    "        sampler = lambda x: random.sample(x, nb_samples)\n",
    "    else:\n",
    "        sampler = lambda x: x\n",
    "    images_labels = [(i, os.path.join(path, image))\n",
    "                     for i, path in zip(labels, paths)\n",
    "                     for image in sampler(os.listdir(path))]\n",
    "    if shuffle:\n",
    "        random.shuffle(images_labels)\n",
    "    return images_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_file_to_array(filename, dim_input):\n",
    "    \"\"\"\n",
    "    Takes an image path and returns numpy array\n",
    "    Args:\n",
    "        filename: Image filename\n",
    "        dim_input: Flattened shape of image\n",
    "    Returns:\n",
    "        1 channel image\n",
    "    \"\"\"\n",
    "    image = misc.imread(filename)\n",
    "    image = image.reshape([dim_input])\n",
    "    image = image.astype(np.float32) / 255.0\n",
    "    image = 1.0 - image\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(logs, NUM_CLASSES, NUM_SAMPLES):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    steps = [x[0] for x in logs]\n",
    "    train_loss = [x[1] for x in logs]\n",
    "    test_loss = [x[2] for x in logs]\n",
    "    acc = [x[3] for x in logs]\n",
    "    ax.plot(steps, train_loss, label = 'train loss')\n",
    "    ax.plot(steps, test_loss, label = 'test_loss')\n",
    "    ax.plot(steps, acc, label = 'accuracy')\n",
    "    ax.set(xlabel='Iterations', \n",
    "           title='MANN: {}-way classification, {}-shot'.format(NUM_CLASSES, NUM_SAMPLES))\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "    plt.savefig(\"{}-{}.png\".format(NUM_CLASSES, NUM_SAMPLES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(object):\n",
    "    \n",
    "    def __init__(self, num_classes, num_samples_per_class):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_classes: Number of classes for classification (K-way)\n",
    "            num_samples_per_class: num samples to generate per class in one batch\n",
    "            batch_size: size of meta batch size (e.g. number of functions)\n",
    "        \"\"\"\n",
    "        self.num_samples_per_class = num_samples_per_class\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        data_folder = './omniglot_resized'\n",
    "        \n",
    "        self.img_size = (28, 28)\n",
    "        self.dim_input = np.prod(self.img_size)\n",
    "        self.dim_output = self.num_classes\n",
    "        \n",
    "        character_folders = [os.path.join(data_folder, family, character)\n",
    "                             for family in os.listdir(data_folder)\n",
    "                             if os.path.isdir(os.path.join(data_folder, family))\n",
    "                             for character in os.listdir(os.path.join(data_folder, family))\n",
    "                             if os.path.isdir(os.path.join(data_folder, family, character))]\n",
    "        \n",
    "        random.seed(1)\n",
    "        random.shuffle(character_folders)\n",
    "        \n",
    "        # using roughly 20% of data for meta-testing (1200:423)\n",
    "        num_train = 1200\n",
    "        \n",
    "        self.metatrain_character_folders = character_folders[:num_train]\n",
    "        self.metatest_character_folders = character_folders[num_train:]\n",
    "        \n",
    "    def sample_batch(self, batch_type, batch_size):\n",
    "        \"\"\"\n",
    "        Samples a batch for training or testing\n",
    "        Args:\n",
    "            batch_type: train/test\n",
    "        Returns:\n",
    "            A a tuple of (1) Image batch and (2) Label batch where\n",
    "            image batch has shape [B, K, N, 784] and label batch has shape [B, K, N, N]\n",
    "            where B is batch size, K is number of samples per class, N is number of classes\n",
    "        \"\"\"\n",
    "        if batch_type == \"train\":\n",
    "            folders = self.metatrain_character_folders\n",
    "        elif batch_type == \"test\":\n",
    "            folders = self.metatest_character_folders\n",
    "            \n",
    "        B, K, N = batch_size, self.num_samples_per_class, self.num_classes\n",
    "        \n",
    "        all_image_batches = np.zeros((B, K, N, self.dim_input))\n",
    "        all_label_batches = np.zeros((B, K, N, N))\n",
    "\n",
    "        for batch_idx in range(B):\n",
    "            sampled_classes = np.random.choice(folders, N, replace = False)\n",
    "            one_hot_labels = np.eye(N)\n",
    "            assert K == self.num_samples_per_class\n",
    "            images_and_labels = get_images(sampled_classes, one_hot_labels, nb_samples=K, shuffle=False)\n",
    "            \n",
    "            images_train = []\n",
    "            images_test = []\n",
    "            labels_train = []\n",
    "            labels_test = []\n",
    "            for i, (label, image_path) in enumerate(images_and_labels):\n",
    "                if i % K == 0:\n",
    "                    images_test.append(image_path)\n",
    "                    labels_test.append(label)\n",
    "                else:\n",
    "                    images_train.append(image_path)\n",
    "                    labels_train.append(label)\n",
    "\n",
    "            images_train, labels_train = shuffle(images_train, labels_train)\n",
    "            images_test, labels_test = shuffle(images_test, labels_test)\n",
    " \n",
    "            \n",
    "            images_train = [image_file_to_array(x, self.dim_input) for x in images_train]\n",
    "            images_test = [image_file_to_array(x, self.dim_input) for x in images_test]\n",
    "            \n",
    "            image_batches_train = np.array(images_train)\n",
    "            label_batches_train = np.array(labels_train)\n",
    "            image_batches_test = np.array(images_test)\n",
    "            label_batches_test = np.array(labels_test)\n",
    "            \n",
    "            image_batches = np.concatenate([image_batches_train, image_batches_test], axis = 0).reshape(K, N, self.dim_input)\n",
    "            label_batches = np.concatenate([label_batches_train, label_batches_test], axis = 0).reshape(K, N, N)\n",
    "            \n",
    "            all_image_batches[batch_idx, :, :, :] = image_batches\n",
    "            all_label_batches[batch_idx, :, :, :] = label_batches\n",
    "                \n",
    "        return all_image_batches, all_label_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/damian/Code/stanford_ml_mt/sample_env/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "num_classes = 4\n",
    "num_samples_per_class = 5\n",
    "batch_size = 16\n",
    "\n",
    "generator = DataGenerator(num_classes, num_samples_per_class)\n",
    "batch_images, batch_labels = generator.sample_batch(\"train\", batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAALF0lEQVR4nO3dXahl9XnH8e+vdhyJSWEmtsPUSJMGb6TQSTlMC5FikabGmzE3krkIFoSTiwgJ5CKSXsRLKU1CL0pgUiXTkhoCieiFNLFDQHIjHsXqqGm1MpKZjk6DFzGFji95enHWhKOeN/de+8XzfD+w2Wv/1zp7PSzmN+vlv9b+p6qQtPf91qILkDQfhl1qwrBLTRh2qQnDLjXx2/Nc2eXZX1dw5TxXKbXyf/wvr9fFbDZvqrAnuQn4e+Ay4B+r6u7tlr+CK/nT3DjNKiVt49E6teW8iQ/jk1wG/APwaeA64HiS6yb9PkmzNc05+1Hghap6sapeB74HHBunLEljmybsVwM/3/D57ND2NklWk6wlWXuDi1OsTtI0Zn41vqpOVNVKVa3sY/+sVydpC9OE/RxwzYbPHxnaJC2hacL+GHBtko8luRz4LPDgOGVJGtvEXW9V9WaSO4Afsd71dm9VPTNaZZJGNVU/e1U9BDw0Ui2SZsjbZaUmDLvUhGGXmjDsUhOGXWrCsEtNGHapCcMuNWHYpSYMu9SEYZeaMOxSE4ZdasKwS00YdqkJwy41YdilJgy71IRhl5ow7FIThl1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhOGXWrCsEtNTDVkc5IzwGvAW8CbVbUyRlGSxjdV2Ad/UVW/GOF7JM2Qh/FSE9OGvYAfJ3k8yepmCyRZTbKWZO0NLk65OkmTmvYw/vqqOpfk94CHk/ysqh7ZuEBVnQBOAPxODtaU65M0oan27FV1bni/ANwPHB2jKEnjmzjsSa5M8qFL08CngNNjFSZpXNMcxh8C7k9y6Xv+par+dZSqJI1u4rBX1YvAH49Yi6QZsutNasKwS00YdqkJwy41YdilJsZ4EGYp/Oi/n5zp9//V7x+Z6fcvq1lvV73brP6tuWeXmjDsUhOGXWrCsEtNGHapCcMuNWHYpSb2TD+7NKa9eF+Fe3apCcMuNWHYpSYMu9SEYZeaMOxSE4ZdamLP9LNP2y+6zM9tz7K2abfbXuyP3qvcs0tNGHapCcMuNWHYpSYMu9SEYZeaMOxSE3umn32Z+Zv2WgY77tmT3JvkQpLTG9oOJnk4yfPD+4HZlilpWrs5jP8OcNM72u4ETlXVtcCp4bOkJbZj2KvqEeDVdzQfA04O0yeBW0auS9LIJj1nP1RV54fpl4FDWy2YZBVYBbiCD0y4OknTmvpqfFUVUNvMP1FVK1W1so/9065O0oQmDfsrSQ4DDO8XxitJ0ixMGvYHgduG6duAB8YpR9Ks7HjOnuQ+4AbgqiRnga8BdwPfT3I78BJw6yyLXAbb9ZX7TLjeD3YMe1Ud32LWjSPXImmGvF1WasKwS00YdqkJwy41YdilJnzEdQns9AisXXMag3t2qQnDLjVh2KUmDLvUhGGXmjDsUhOGXWrCfvY52KmffKd+9mXuh1/m2vR27tmlJgy71IRhl5ow7FIThl1qwrBLTRh2qQn72Xdpkf3Fy7zuWQ9HrfG4Z5eaMOxSE4ZdasKwS00YdqkJwy41YdilJgy71MSOYU9yb5ILSU5vaLsrybkkTw6vm2dbpqRp7WbP/h3gpk3av1lVR4bXQ+OWJWlsO4a9qh4BXp1DLZJmaJpz9juSPDUc5h/YaqEkq0nWkqy9wcUpVidpGpOG/VvAx4EjwHng61stWFUnqmqlqlb2sX/C1Uma1kRhr6pXquqtqvo18G3g6LhlSRrbRGFPcnjDx88Ap7daVtJy2PF59iT3ATcAVyU5C3wNuCHJEaCAM8DnZ1jj0vOZbr0f7Bj2qjq+SfM9M6hF0gx5B53UhGGXmjDsUhOGXWrCsEtN+FPSI9jLwxLbrbh3uGeXmjDsUhOGXWrCsEtNGHapCcMuNWHYpSbsZ9dU9vI9BnuNe3apCcMuNWHYpSYMu9SEYZeaMOxSE4ZdasKwS00YdqkJwy41YdilJgy71IRhl5ow7FIThl1qwufZd2m7309/Pz/T7e/C97Hjnj3JNUl+kuTZJM8k+eLQfjDJw0meH94PzL5cSZPazWH8m8CXq+o64M+ALyS5DrgTOFVV1wKnhs+SltSOYa+q81X1xDD9GvAccDVwDDg5LHYSuGVWRUqa3ns6Z0/yUeATwKPAoao6P8x6GTi0xd+sAqsAV/CBSeuUNKVdX41P8kHgB8CXquqXG+dVVQG12d9V1YmqWqmqlX3sn6pYSZPbVdiT7GM96N+tqh8Oza8kOTzMPwxcmE2Jksaw42F8kgD3AM9V1Tc2zHoQuA24e3h/YCYVzslO3WfbdVHt1H016665WXafvZ+7FfV2uzln/yTwOeDpJJf+VX2V9ZB/P8ntwEvArbMpUdIYdgx7Vf0UyBazbxy3HEmz4u2yUhOGXWrCsEtNGHapCcMuNeEjrnOwzI+R2o/eh3t2qQnDLjVh2KUmDLvUhGGXmjDsUhOGXWrCfvZdsj9a73fu2aUmDLvUhGGXmjDsUhOGXWrCsEtNGHapCcMuNWHYpSYMu9SEYZeaMOxSE4ZdasKwS00YdqmJHcOe5JokP0nybJJnknxxaL8rybkkTw6vm2dfrqRJ7ebHK94EvlxVTyT5EPB4koeHed+sqr+bXXmSxrKb8dnPA+eH6deSPAdcPevCJI3rPZ2zJ/ko8Ang0aHpjiRPJbk3yYEt/mY1yVqStTe4OFWxkia367An+SDwA+BLVfVL4FvAx4EjrO/5v77Z31XViapaqaqVfewfoWRJk9hV2JPsYz3o362qHwJU1StV9VZV/Rr4NnB0dmVKmtZursYHuAd4rqq+saH98IbFPgOcHr88SWPZzdX4TwKfA55Ocmns4a8Cx5McAQo4A3x+JhVKGsVursb/FMgmsx4avxxJs+IddFIThl1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhOGXWrCsEtNGHapCcMuNWHYpSZSVfNbWfI/wEsbmq4CfjG3At6bZa1tWesCa5vUmLX9QVX97mYz5hr2d608WauqlYUVsI1lrW1Z6wJrm9S8avMwXmrCsEtNLDrsJxa8/u0sa23LWhdY26TmUttCz9klzc+i9+yS5sSwS00sJOxJbkryH0leSHLnImrYSpIzSZ4ehqFeW3At9ya5kOT0hraDSR5O8vzwvukYewuqbSmG8d5mmPGFbrtFD38+93P2JJcB/wn8JXAWeAw4XlXPzrWQLSQ5A6xU1cJvwEjy58CvgH+qqj8a2v4WeLWq7h7+ozxQVV9ZktruAn616GG8h9GKDm8cZhy4BfhrFrjttqnrVuaw3RaxZz8KvFBVL1bV68D3gGMLqGPpVdUjwKvvaD4GnBymT7L+j2XutqhtKVTV+ap6Yph+Dbg0zPhCt902dc3FIsJ+NfDzDZ/PslzjvRfw4ySPJ1lddDGbOFRV54fpl4FDiyxmEzsO4z1P7xhmfGm23STDn0/LC3Tvdn1V/QnwaeALw+HqUqr1c7Bl6jvd1TDe87LJMOO/schtN+nw59NaRNjPAdds+PyRoW0pVNW54f0CcD/LNxT1K5dG0B3eLyy4nt9YpmG8NxtmnCXYdosc/nwRYX8MuDbJx5JcDnwWeHABdbxLkiuHCyckuRL4FMs3FPWDwG3D9G3AAwus5W2WZRjvrYYZZ8HbbuHDn1fV3F/Azaxfkf8v4G8WUcMWdf0h8O/D65lF1wbcx/ph3RusX9u4HfgwcAp4Hvg34OAS1fbPwNPAU6wH6/CCarue9UP0p4Anh9fNi95229Q1l+3m7bJSE16gk5ow7FIThl1qwrBLTRh2qQnDLjVh2KUm/h/KVnh9mJ3kxQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAALc0lEQVR4nO3dX6hl5XnH8e+vdhyJSWCmtsPUSJMGb6RQUw6TQqVYpKnxRnMjmYtiQXpyESGBXFTsRbyU0iTkogQmVTIpqSGQiF5IEzsEbG7EUayO2lYrSpyOToIXmkL9+/TiLMNRzzn7zN5r/5nzfD+w2XuvtfZZj0t/vmuvd737TVUhae/7jWUXIGkxDLvUhGGXmjDsUhOGXWriNxe5swuzvy7i4kXuUmrl//hf3qjXs9W6mcKe5Frgm8AFwD9W1R07bX8RF/PpXDPLLiXt4KE6se26qU/jk1wA/APwWeAK4GiSK6b9e5Lma5bv7EeAZ6vquap6A/g+cP04ZUka2yxhvxT4+ab3Lw7L3iPJepKTSU6+yesz7E7SLOZ+Nb6qjlXVWlWt7WP/vHcnaRuzhP00cNmm9x8blklaQbOE/WHg8iSfSHIh8HngvnHKkjS2qbvequqtJLcAP2aj6+2uqnpytMokjWqmfvaquh+4f6RaJM2Rt8tKTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhOGXWrCsEtNGHapCcMuNWHYpSYMu9SEYZeaMOxSE4ZdasKwS00YdqkJwy41YdilJgy71MRCp2zeq378P4/N9Pm/+N0rR6pkfJP+2Va5dr2XLbvUhGGXmjDsUhOGXWrCsEtNGHapCcMuNWHYpSZmuqkmyfPAa8DbwFtVtTZGUZLGN8YddH9WVb8c4e9ImiNP46UmZg17AT9J8kiS9a02SLKe5GSSk2/y+oy7kzStWU/jr6qq00l+B3ggyX9U1YObN6iqY8AxgI/mYM24P0lTmqllr6rTw/NZ4B7gyBhFSRrf1GFPcnGSj7z7GvgMcGqswiSNa5bT+EPAPUne/Tv/XFX/MkpV55lJY7onjQl3zPh0ZvkdgY7HdOqwV9VzwB+OWIukObLrTWrCsEtNGHapCcMuNWHYpSb8KekFmLVrThqDLbvUhGGXmjDsUhOGXWrCsEtNGHapCcMuNWE/+3mg6xDYvTwV9jLYsktNGHapCcMuNWHYpSYMu9SEYZeaMOxSE/azrwDHu0/HfvRzY8suNWHYpSYMu9SEYZeaMOxSE4ZdasKwS03Yz74H7NQPv8p90V3H6S/LxJY9yV1JziY5tWnZwSQPJHlmeD4w3zIlzWo3p/HfAa5937JbgRNVdTlwYngvaYVNDHtVPQi88r7F1wPHh9fHgRtGrkvSyKb9zn6oqs4Mr18CDm23YZJ1YB3gIj405e4kzWrmq/FVVUDtsP5YVa1V1do+9s+6O0lTmjbsLyc5DDA8nx2vJEnzMG3Y7wNuGl7fBNw7TjmS5mXid/YkdwNXA5ckeRH4KnAH8IMkNwMvADfOs8juzufx7qtcWzcTw15VR7dZdc3ItUiaI2+XlZow7FIThl1qwrBLTRh2qQmHuO5xqzyM1CGsi2XLLjVh2KUmDLvUhGGXmjDsUhOGXWrCsEtN2M++B+zUXz2pn33WIagOYT1/2LJLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhP2s2uuHLO+OmzZpSYMu9SEYZeaMOxSE4ZdasKwS00YdqkJ+9n3uHlP92w/+vljYsue5K4kZ5Oc2rTs9iSnkzw2PK6bb5mSZrWb0/jvANdusfwbVXXl8Lh/3LIkjW1i2KvqQeCVBdQiaY5muUB3S5LHh9P8A9ttlGQ9yckkJ9/k9Rl2J2kW04b9W8AngSuBM8DXttuwqo5V1VpVre1j/5S7kzSrqcJeVS9X1dtV9Q7wbeDIuGVJGttUYU9yeNPbzwGntttW0mqY2M+e5G7gauCSJC8CXwWuTnIlUMDzwBfmWKOkEUwMe1Ud3WLxnXOoRdIcebus1IRhl5ow7FIThl1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhOGXWrCsEtN+FPSe9ysPxWtvcOWXWrCsEtNGHapCcMuNWHYpSYMu9SEYZeasJ+9uVmnXJ7Uj++UzqvDll1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmrCffQ9Y5THrO9VmH/xiTWzZk1yW5KdJnkryZJIvDcsPJnkgyTPD84H5lytpWrs5jX8L+EpVXQH8MfDFJFcAtwInqupy4MTwXtKKmhj2qjpTVY8Or18DngYuBa4Hjg+bHQdumFeRkmZ3Tt/Zk3wc+BTwEHCoqs4Mq14CDm3zmXVgHeAiPjRtnZJmtOur8Uk+DPwQ+HJVvbp5XVUVUFt9rqqOVdVaVa3tY/9MxUqa3q7CnmQfG0H/XlX9aFj8cpLDw/rDwNn5lChpDBNP45MEuBN4uqq+vmnVfcBNwB3D871zqVArbVL32U5dbw6PXazdfGf/E+AvgSeSvPtv5zY2Qv6DJDcDLwA3zqdESWOYGPaq+hmQbVZfM245kubF22WlJgy71IRhl5ow7FIThl1qwiGu54FZhrAuu696p/2v8tDcvciWXWrCsEtNGHapCcMuNWHYpSYMu9SEYZeasJ99D1h2X/q8ON59XLbsUhOGXWrCsEtNGHapCcMuNWHYpSYMu9SE/examll+c17nzpZdasKwS00YdqkJwy41YdilJgy71IRhl5rYzfzslwHfBQ4BBRyrqm8muR34a+AXw6a3VdX98yp0L7M/eTqOdz83u7mp5i3gK1X1aJKPAI8keWBY942q+vv5lSdpLLuZn/0McGZ4/VqSp4FL512YpHGd03f2JB8HPgU8NCy6JcnjSe5KcmCbz6wnOZnk5Ju8PlOxkqa367An+TDwQ+DLVfUq8C3gk8CVbLT8X9vqc1V1rKrWqmptH/tHKFnSNHYV9iT72Aj696rqRwBV9XJVvV1V7wDfBo7Mr0xJs5oY9iQB7gSerqqvb1p+eNNmnwNOjV+epLGkqnbeILkK+DfgCeCdYfFtwFE2TuELeB74wnAxb1sfzcH6dK6ZsWRpd3bqmtur3XIP1QlerVey1brdXI3/GbDVh+1Tl84j3kEnNWHYpSYMu9SEYZeaMOxSE4ZdasKfktaetVf70qdlyy41YdilJgy71IRhl5ow7FIThl1qwrBLTUwczz7qzpJfAC9sWnQJ8MuFFXBuVrW2Va0LrG1aY9b2e1X121utWGjYP7Dz5GRVrS2tgB2sam2rWhdY27QWVZun8VIThl1qYtlhP7bk/e9kVWtb1brA2qa1kNqW+p1d0uIsu2WXtCCGXWpiKWFPcm2S/0zybJJbl1HDdpI8n+SJJI8lObnkWu5KcjbJqU3LDiZ5IMkzw/OWc+wtqbbbk5wejt1jSa5bUm2XJflpkqeSPJnkS8PypR67HepayHFb+Hf2JBcA/wX8OfAi8DBwtKqeWmgh20jyPLBWVUu/ASPJnwK/Ar5bVX8wLPs74JWqumP4H+WBqvqbFantduBXy57Ge5it6PDmacaBG4C/YonHboe6bmQBx20ZLfsR4Nmqeq6q3gC+D1y/hDpWXlU9CLzyvsXXA8eH18fZ+I9l4bapbSVU1ZmqenR4/Rrw7jTjSz12O9S1EMsI+6XAzze9f5HVmu+9gJ8keSTJ+rKL2cKhTdNsvQQcWmYxW5g4jfcivW+a8ZU5dtNMfz4rL9B90FVV9UfAZ4EvDqerK6k2voOtUt/prqbxXpQtphn/tWUeu2mnP5/VMsJ+Grhs0/uPDctWQlWdHp7PAvewelNRv/zuDLrD89kl1/NrqzSN91bTjLMCx26Z058vI+wPA5cn+USSC4HPA/ctoY4PSHLxcOGEJBcDn2H1pqK+D7hpeH0TcO8Sa3mPVZnGe7tpxlnysVv69OdVtfAHcB0bV+T/G/jbZdSwTV2/D/z78Hhy2bUBd7NxWvcmG9c2bgZ+CzgBPAP8K3BwhWr7Jzam9n6cjWAdXlJtV7Fxiv448NjwuG7Zx26HuhZy3LxdVmrCC3RSE4ZdasKwS00YdqkJwy41YdilJgy71MT/A/uBrlB+cHZcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_idx = 15\n",
    "image_index = -1\n",
    "sample_images, sample_labels = batch_images[batch_idx, image_index, :, :], batch_labels[batch_idx, image_index, :, :]\n",
    "for i, j in zip(sample_images, sample_labels):\n",
    "    print(j)\n",
    "    plt.imshow(np.uint8(i.reshape(28, 28)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MANN(tf.keras.Model):\n",
    "    def __init__(self, num_classes, samples_per_class, lstm_size, conv = False):\n",
    "        super(MANN, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.samples_per_class = samples_per_class\n",
    "        self.conv = conv\n",
    "        \n",
    "        self.conv_1 = tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_initializer = 'he_uniform')\n",
    "        self.dense_1 = tf.keras.layers.Dense(100)\n",
    "        self.layer_pool = tf.keras.layers.MaxPooling2D((2,2))\n",
    "        self.layer_flatten = tf.keras.layers.Flatten()\n",
    "        \n",
    "        self.lstm_1 = tf.keras.layers.LSTM(lstm_size, return_sequences = True)\n",
    "        self.lstm_2 = tf.keras.layers.LSTM(num_classes, return_sequences = True)\n",
    "        \n",
    "    def call(self, input_images, input_labels):\n",
    "        \"\"\"\n",
    "        MANN\n",
    "        Args:\n",
    "            input_images: [B, K+1, N, 784] flattened images\n",
    "            labels: [B, K+1, N, N] ground truth labels\n",
    "        Returns:\n",
    "            [B, K+1, N, N] predictions\n",
    "        \"\"\"\n",
    "        B, Kplusone, N, D = input_images.shape\n",
    "        K = Kplusone - 1\n",
    "        input_labels = tf.dtypes.cast(input_labels, tf.float32)\n",
    "        input_labels = tf.concat([input_labels[:, :-1],\n",
    "                                  tf.zeros_like(input_labels[:, -1:])], axis = 1)        \n",
    "        if self.conv:\n",
    "            image_dims = 28\n",
    "            input_images = tf.reshape(input_images, (B * Kplusone * N, image_dims, image_dims, 1))\n",
    "            input_images = self.dense_1(self.layer_flatten(self.layer_pool(self.conv_1(input_images))))\n",
    "            input_images = tf.reshape(input_images, (B, Kplusone, N, -1))\n",
    "            x = tf.concat([input_images, input_labels], axis = 3)\n",
    "            x = tf.reshape(x, (B, Kplusone * N, -1))\n",
    "   \n",
    "        else:\n",
    "            x = tf.concat([input_images, input_labels], axis = 3)\n",
    "            x = tf.reshape(x, (B, Kplusone * N, D + N))\n",
    "            \n",
    "        out = self.lstm_2(self.lstm_1(x))\n",
    "        out = tf.reshape(out, (B, Kplusone, N, N))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(preds, labels):\n",
    "    \"\"\"\n",
    "    Computes MANN loss\n",
    "    Args:\n",
    "        preds: [B, K+1, N, N] network output\n",
    "        labels: [B, K+1, N, N] labels\n",
    "    Returns:\n",
    "        scalar loss\n",
    "    \"\"\"\n",
    "    last_y_preds = preds[:, -1:]\n",
    "    last_y_labels = labels[:, -1:]\n",
    "    loss = tf.keras.losses.categorical_crossentropy(last_y_labels, last_y_preds, from_logits=True)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inputs, labels, model, loss_object, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, labels, training=True)\n",
    "        loss = loss_object(predictions, labels)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "    \n",
    "@tf.function\n",
    "def test_step(inputs, labels, model, loss_object):\n",
    "    predictions = model(inputs, labels, training=False)\n",
    "    loss = loss_object(predictions, labels)\n",
    "    return loss, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MANN(NUM_CLASSES = 5, NUM_SAMPLES = 1, META_BATCH_SIZE = 64, ITERATIONS = 50000, LSTM_SIZE = 128, CONV = False):\n",
    "    \"\"\"\n",
    "    NUM_CLASSES        'number of classes used in classification (e.g. 5-way classification)\n",
    "    NUM_SAMPLES        'number of examples used for inner gradient update (K for K-shot learning).'\n",
    "    META_BATCH_SIZE    'number of N-way classification tasks per batch'\n",
    "    \"\"\"\n",
    "    \n",
    "    logs = []\n",
    "\n",
    "    data_generator = DataGenerator(NUM_CLASSES, NUM_SAMPLES + 1)\n",
    "    \n",
    "    o = MANN(NUM_CLASSES, NUM_SAMPLES + 1, LSTM_SIZE, CONV)\n",
    "    loss = loss_function\n",
    "    optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "\n",
    "    for step in range(ITERATIONS):\n",
    "        images_batch, labels_batch = data_generator.sample_batch('train', META_BATCH_SIZE)\n",
    "        train_loss = train_step(images_batch, labels_batch, o, loss, optimizer)\n",
    "        if step % 1000 == 0:\n",
    "            print(\"*\" * 5 + \"Iteration no. {}\".format(step) + \"*\" * 5)\n",
    "\n",
    "            images_batch_test, labels_batch_test = data_generator.sample_batch('test', 300)\n",
    "            test_loss, preds = test_step(images_batch_test, labels_batch_test, o, loss)\n",
    "            preds = preds.numpy().reshape(-1, NUM_SAMPLES + 1, NUM_CLASSES, NUM_CLASSES)\n",
    "            preds = preds[:, -1, :, :].argmax(2)\n",
    "            labels_batch_test = labels_batch_test[:, -1, :, :].argmax(2)\n",
    "\n",
    "            print(\"Train Loss: {} Test Loss: {}\".format(train_loss.numpy(), test_loss.numpy()))\n",
    "            accuracy = (1.0 * (preds == labels_batch_test)).mean()\n",
    "            print(\"Test Accuracy\", accuracy)\n",
    "\n",
    "            logs.append((step, train_loss, test_loss, accuracy))\n",
    "\n",
    "    plot_results(logs, NUM_CLASSES, NUM_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer mann is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/damian/Code/stanford_ml_mt/sample_env/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Iteration no. 0*****\n",
      "Train Loss: 0.6941792964935303 Test Loss: 0.6959450244903564\n",
      "Test Accuracy 0.5\n",
      "*****Iteration no. 1000*****\n",
      "Train Loss: 0.6293325424194336 Test Loss: 0.5899530649185181\n",
      "Test Accuracy 0.6033333333333334\n",
      "*****Iteration no. 2000*****\n",
      "Train Loss: 0.45721012353897095 Test Loss: 0.5178144574165344\n",
      "Test Accuracy 0.6866666666666666\n",
      "*****Iteration no. 3000*****\n",
      "Train Loss: 0.40829434990882874 Test Loss: 0.43099862337112427\n",
      "Test Accuracy 0.85\n",
      "*****Iteration no. 4000*****\n",
      "Train Loss: 0.381076842546463 Test Loss: 0.3954070210456848\n",
      "Test Accuracy 0.8483333333333334\n",
      "*****Iteration no. 5000*****\n",
      "Train Loss: 0.3802157938480377 Test Loss: 0.336791068315506\n",
      "Test Accuracy 0.8916666666666667\n",
      "*****Iteration no. 6000*****\n",
      "Train Loss: 0.3617760241031647 Test Loss: 0.3291057050228119\n",
      "Test Accuracy 0.8983333333333333\n",
      "*****Iteration no. 7000*****\n",
      "Train Loss: 0.3642581105232239 Test Loss: 0.3533407151699066\n",
      "Test Accuracy 0.875\n",
      "*****Iteration no. 8000*****\n",
      "Train Loss: 0.265325129032135 Test Loss: 0.32841700315475464\n",
      "Test Accuracy 0.9\n",
      "*****Iteration no. 9000*****\n",
      "Train Loss: 0.3147777318954468 Test Loss: 0.3538263440132141\n",
      "Test Accuracy 0.89\n",
      "*****Iteration no. 10000*****\n",
      "Train Loss: 0.3872714042663574 Test Loss: 0.3009839951992035\n",
      "Test Accuracy 0.9183333333333333\n",
      "*****Iteration no. 11000*****\n",
      "Train Loss: 0.28241461515426636 Test Loss: 0.3270054757595062\n",
      "Test Accuracy 0.8983333333333333\n",
      "*****Iteration no. 12000*****\n",
      "Train Loss: 0.28690317273139954 Test Loss: 0.29317644238471985\n",
      "Test Accuracy 0.9283333333333333\n"
     ]
    }
   ],
   "source": [
    "# fix K vary N\n",
    "for NUM_CLASSES in [2,3,4]:\n",
    "    NUM_SAMPLES = 1\n",
    "    train_MANN(NUM_CLASSES, NUM_SAMPLES, CONV = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sample_env",
   "language": "python",
   "name": "sample_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
